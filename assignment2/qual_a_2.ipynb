{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EoIT 2.2\n",
    "\n",
    "EoIT 2.5\n",
    "\n",
    "EoIT 2.8\n",
    "\n",
    "EoIT 2.9\n",
    "\n",
    "EoIT 2.18\n",
    "\n",
    "EoIT 2.28\n",
    "\n",
    "EoIT 2.35\n",
    "\n",
    "EoIT 2.36\n",
    "\n",
    "EoIT 4.3\n",
    "\n",
    "EoIT 4.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Entropy of functions. Let X be a random variable taking on a\n",
    "finite number of values. What is the (general) inequality relationship of H (X) and H (Y ) if\n",
    "\n",
    "(a) Y = $2^X$?\n",
    "\n",
    "(b) Y = $cos X$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Zero conditional entropy. Show that if H (Y|X) = 0, then Y is\n",
    "a function of X [i.e., for all x with p(x) > 0, there is only one\n",
    "possible value of y with p(x, y) > 0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8 Drawing with and without replacement. An urn contains r red, w\n",
    "white, and b black balls. Which has higher entropy, drawing k ≥ 2\n",
    "balls from the urn with replacement or without replacement? Set it\n",
    "up and show why. (There is both a difficult way and a relatively\n",
    "simple way to do this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9 Metric. A function ρ(x, y) is a metric if for all x, y,\n",
    "\n",
    "• ρ(x, y) ≥ 0.\n",
    "\n",
    "• ρ(x, y) = ρ(y, x).\n",
    "\n",
    "• ρ(x, y) = 0 if and only if x = y.\n",
    "\n",
    "• ρ(x, y) + ρ(y, z) ≥ ρ(x, z).\n",
    "\n",
    "(a) Show that ρ(X, Y ) = H (X|Y ) + H (Y|X) satisfies the first,\n",
    "second, and fourth properties above. If we say that X = Y if\n",
    "there is a one-to-one function mapping from X to Y, the third\n",
    "property is also satisfied, and ρ(X, Y ) is a metric.\n",
    "\n",
    "(b) Verify that ρ(X, Y ) can also be expressed as\n",
    "\n",
    "ρ(X, Y ) = H (X) + H (Y ) − 2I (X; Y ) (2.172)\n",
    "\n",
    "= H (X, Y ) − I (X; Y ) (2.173)\n",
    "\n",
    "= 2H (X, Y ) − H (X) − H (Y ). (2.174)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.18 World Series. The World Series is a seven-game series that terminates as soon as either team wins four games. Let X be the random\n",
    "variable that represents the outcome of a World Series between\n",
    "teams A and B; possible values of X are AAAA, BABABAB, and\n",
    "BBBAAAA. Let Y be the number of games played, which ranges\n",
    "from 4 to 7. Assuming that A and B are equally matched and that the games are independent, calculate H (X), H (Y ), H (Y|X), and\n",
    "H (X|Y )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.28 Mixing increases entropy. Show that the entropy of the probability distribution, (p1,...,pi,...,pj ,...,pm), is less than the\n",
    "entropy of the distribution (p1,..., $\\frac{pi+pj}{2}$ ,..., $\\frac{pi+pj}{2}$,...,pm)\n",
    " Show that in general any transfer of probability that\n",
    "makes the distribution more uniform increases the entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.35 Relative entropy is not symmetric.\n",
    "Let the random variable X have three possible outcomes {a, b, c}.\n",
    "Consider two distributions on this random variable:\n",
    "\n",
    "| symbol | p(x) | q(x) |\n",
    "|--------|------|------|\n",
    "| a      | $\\frac{1}{2}$ | $\\frac{1}{3}$ |\n",
    "| b      | $\\frac{1}{4}$ | $\\frac{1}{3}$ |\n",
    "| c      | $\\frac{1}{4}$ | $\\frac{1}{3}$ |\n",
    "\n",
    "Calculate H (p), H (q), D(p||q), and D(q||p). Verify that in this\n",
    "case, D(p||q) != D(q||p).\n",
    "\n",
    "Use D_kL(P||Q) to solve.  (-Sum over X p(X=x) * log (p(X=X)/q(X=x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.36 Symmetric relative entropy. Although, as Problem 2.35 shows,\n",
    "D(p||q) != D(q||p) in general, there could be distributions for\n",
    "which equality holds. Give an example of two distributions p and\n",
    "q on a binary alphabet such that D(p||q) = D(q||p) (other than\n",
    "the trivial case p = q)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
